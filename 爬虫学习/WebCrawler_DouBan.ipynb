{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 豆瓣top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://movie.douban.com/top250\n",
    "#每页有25条电影，共有10页。\n",
    "#电影列表在页面上的位置为一个class属性为grid_view的ol标签中。\n",
    "#每条电影信息放在这个ol标签的一个li标签里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_URL = 'http://movie.douban.com/top250'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_page(url):\n",
    "    #手动指定User-Agent为Chrome浏览器，再此访问就得到了真实的网页源码。服务器通过校验请求的U-A来识别爬虫\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36'\n",
    "    }\n",
    "    data = requests.get(url).content\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html):\n",
    "    #创建了一个BeautifulSoup对象\n",
    "    soup = BeautifulSoup(html)\n",
    "    #使用刚刚创建的对象搜索这篇html文档中查找那个class为grid_view的ol标签\n",
    "    movie_list_soup = soup.find('ol', attrs={'class': 'grid_view'})\n",
    "    movie_name_list = []\n",
    "    for movie_li in movie_list_soup.find_all('li'):\n",
    "        detail = movie_li.find('div', attrs={'class': 'hd'})\n",
    "        movie_name = detail.find('span', attrs={'class': 'title'}).getText()\n",
    "        movie_name_list.append(movie_name)\n",
    "        #print movie_name\n",
    "    next_page = soup.find('span', attrs={'class': 'next'}).find('a')\n",
    "    #如果有下一页，则返回下一页的url\n",
    "    if next_page:\n",
    "        return movie_name_list, DOWNLOAD_URL + next_page['href']\n",
    "    return movie_name_list, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = DOWNLOAD_URL\n",
    "\n",
    "    with codecs.open('movies', 'wb', encoding='utf-8') as fp:\n",
    "        while url:\n",
    "            html = download_page(url)\n",
    "            movies, url = parse_html(html)\n",
    "            fp.write(u'{movies}\\n'.format(movies='\\n'.join(movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
